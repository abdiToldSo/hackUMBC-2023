# -*- coding: utf-8 -*-
"""FINAL_HACKUMBC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cT_5hVilDWj3tXGA_IKGvteX92XQk-AQ
"""

#Import neccesary libraries
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

#read file
df = pd.read_csv("/CSV_Netflix_Dataset_Latest_2021.csv")

# Function to get the recommended movies
def get_recommendations(title, top_n=20):
    # Find the index of the movie with the given title
    idx = df[df['Title'] == title].index[0]

    # Get the cosine similarity scores for the movie
    similarity_scores = list(enumerate(similarity[idx]))

    # Sort the similarity scores in descending order
    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)

    # Get the top_n movie indices
    movie_indices = [i[0] for i in similarity_scores[1:top_n+1]]

    # Return the top_n most similar movies
    return df['Title'].iloc[movie_indices]

#collating list
mega_list = []

#past seen movies
movie_list = ["The Godfather", "Schindlers List", "VINLAND SAGA"] #Extracted from an API

#movie to be worked on
for x in movie_list:
  movie_name = x

  #vectorizer
  tfidf = TfidfVectorizer(stop_words='english')
  df['Summary'] = df['Summary'].fillna('')
  tfidf_matrix = tfidf.fit_transform(df['Summary'])
  tfidf_matrix.shape
  cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
  df = df[~df['Title'].isna()]

  indices = pd.Series(df.index, index=df['Title'])
  indices = indices[~indices.index.duplicated(keep='last')]

  indices = pd.Series(df.index, index=df['Title'])
  indices = indices[~indices.index.duplicated(keep='last')]

  target_movie_index = df.loc[df['Title'] == movie_name].index[0]

  similarity_scores = pd.DataFrame(cosine_sim[target_movie_index], columns=["score"])
  similarity_scores

  movie_indices = similarity_scores.sort_values("score", ascending=False)[1:50].index

  summary = df['Title'].iloc[movie_indices]
  summary_list = list(summary)

  subset_sum = df[df['Title'].isin(summary_list)]

  items_data = subset_sum[["Title", "Genre", "Tags"]]
  user_pref_df = subset_sum[["Genre", "Tags"]]

  #print(items_data.head())

  #remove na
  df['Genre'].fillna('Unknown', inplace=True)
  df['Tags'].fillna('Unknown', inplace=True)

  # Create a binary feature matrix for the genres
  genre_matrix = pd.get_dummies( df['Genre'].str.split("|").apply(pd.Series).stack()).sum(level=0)
  tag_matrix = pd.get_dummies( df['Tags'].str.split("|").apply(pd.Series).stack()).sum(level=0)

  # Concatenate the genre and tag matrices horizontally
  feature_matrix = pd.concat([genre_matrix, tag_matrix], axis=1)

  # Compute the cosine similarity matrix
  similarity = cosine_similarity(feature_matrix)

  # Get the recommended movies
  #print("Top 50 similar movies:")
  #print(get_recommendations(movie_name))

  char_list = list(get_recommendations(movie_name))

  #print(char_list)
  mega_list.append(char_list)

unique = set(char_list)

#Additional recommendations
special_add_list = ["Mr. Sunshine"] #this list will contain all the special requests put in via checkbox
unique.update(special_add_list)

#Further sorting based on additional parameter

#Pulling 5 Movie titles
subset_unique = df[df['Title'].isin(unique)]
provided = subset_unique.sample(5)
display(provided)

#Names fo the movies
suggested = list[provided["Title"]]
print(suggested)
#This will be on the front end display with the posters, summary and netflix link
#A direct integration to netflixparty is also provided

suggested[0]

# Commented out IPython magic to ensure Python compatibility.
# %%writefile final_app.py
# #Import neccesary libraries
# import pandas as pd
# import numpy as np
# from sklearn.metrics.pairwise import cosine_similarity
# from sklearn.metrics import mean_squared_error
# from sklearn.model_selection import train_test_split
# from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.metrics.pairwise import linear_kernel
# 
# #read file
# df = pd.read_csv("/CSV_Netflix_Dataset_Latest_2021.csv")
# 
# # Function to get the recommended movies
# def get_recommendations(title, top_n=20):
#     # Find the index of the movie with the given title
#     idx = df[df['Title'] == title].index[0]
# 
#     # Get the cosine similarity scores for the movie
#     similarity_scores = list(enumerate(similarity[idx]))
# 
#     # Sort the similarity scores in descending order
#     similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)
# 
#     # Get the top_n movie indices
#     movie_indices = [i[0] for i in similarity_scores[1:top_n+1]]
# 
#     # Return the top_n most similar movies
#     return df['Title'].iloc[movie_indices]
# 
# #collating list
# mega_list = []
# 
# #past seen movies
# movie_list = ["The Godfather", "Schindlers List", "VINLAND SAGA"] #Extracted from an API
# 
# #movie to be worked on
# for x in movie_list:
#   movie_name = x
# 
#   #vectorizer
#   tfidf = TfidfVectorizer(stop_words='english')
#   df['Summary'] = df['Summary'].fillna('')
#   tfidf_matrix = tfidf.fit_transform(df['Summary'])
#   tfidf_matrix.shape
#   cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
#   df = df[~df['Title'].isna()]
# 
#   indices = pd.Series(df.index, index=df['Title'])
#   indices = indices[~indices.index.duplicated(keep='last')]
# 
#   indices = pd.Series(df.index, index=df['Title'])
#   indices = indices[~indices.index.duplicated(keep='last')]
# 
#   target_movie_index = df.loc[df['Title'] == movie_name].index[0]
# 
#   similarity_scores = pd.DataFrame(cosine_sim[target_movie_index], columns=["score"])
#   similarity_scores
# 
#   movie_indices = similarity_scores.sort_values("score", ascending=False)[1:50].index
# 
#   summary = df['Title'].iloc[movie_indices]
#   summary_list = list(summary)
# 
#   subset_sum = df[df['Title'].isin(summary_list)]
# 
#   items_data = subset_sum[["Title", "Genre", "Tags"]]
#   user_pref_df = subset_sum[["Genre", "Tags"]]
# 
#   #print(items_data.head())
# 
#   #remove na
#   df['Genre'].fillna('Unknown', inplace=True)
#   df['Tags'].fillna('Unknown', inplace=True)
# 
#   # Create a binary feature matrix for the genres
#   genre_matrix = pd.get_dummies( df['Genre'].str.split("|").apply(pd.Series).stack()).sum(level=0)
#   tag_matrix = pd.get_dummies( df['Tags'].str.split("|").apply(pd.Series).stack()).sum(level=0)
# 
#   # Concatenate the genre and tag matrices horizontally
#   feature_matrix = pd.concat([genre_matrix, tag_matrix], axis=1)
# 
#   # Compute the cosine similarity matrix
#   similarity = cosine_similarity(feature_matrix)
# 
#   # Get the recommended movies
#   #print("Top 50 similar movies:")
#   #print(get_recommendations(movie_name))
# 
#   char_list = list(get_recommendations(movie_name))
# 
#   #print(char_list)
#   mega_list.append(char_list)
# 
#   unique = set(char_list)
# 
# #Additional recommendations
# special_add_list = ["Mr. Sunshine"] #this list will contain all the special requests put in via checkbox
# 
# #Further sorting based on additional parameter
# 
# #Pulling 5 Movie titles
# subset_unique = df[df['Title'].isin(unique)]
# provided = subset_unique.sample(5)
# display(provided)
# 
# #Names fo the movies
# suggested = list[provided["Title"]]
# print(suggested)
# #This will be on the front end display with the posters, summary and netflix link
# #A direct integration to netflixparty is also provided